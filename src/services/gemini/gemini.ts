import * as fs from "node:fs/promises";
import { GoogleGenAI, type PersonGeneration } from "@google/genai";
import { env } from "env";

/**
 * Reference image for style guidance in generation
 */
export interface ReferenceImage {
  url?: string; // Public URL
  path?: string; // Local file path
  base64?: string; // Base64 data
  mimeType?: string; // Required for base64
}

export interface GenerateImageParams {
  prompt: string;
  aspectRatio?: "1:1" | "3:4" | "4:3" | "9:16" | "16:9";
  numberOfImages?: 1 | 2 | 3 | 4;
  personGeneration?: PersonGeneration;
  referenceImages?: ReferenceImage[]; // Style/reference images
}

export interface EditImageParams {
  prompt: string;
  referenceImages: string[];
  aspectRatio?: "1:1" | "3:4" | "4:3" | "9:16" | "16:9";
}

interface GeminiImagePart {
  inlineData: {
    mimeType: string;
    data: string;
  };
}

export class GeminiClient {
  private readonly client = new GoogleGenAI({ apiKey: env.GEMINI_API_KEY });
  private readonly model = "gemini-2.5-flash-image";
  private readonly visionModel = "gemini-2.0-flash";

  async generateImage(params: GenerateImageParams): Promise<string[]> {
    const numberOfImages = params.numberOfImages ?? 1;
    const images: string[] = [];

    // Build reference image parts once (shared across all generations)
    const refParts: GeminiImagePart[] = [];
    if (params.referenceImages?.length) {
      for (const ref of params.referenceImages) {
        const part = await this.referenceToImagePart(ref);
        refParts.push(part);
      }
    }

    for (let i = 0; i < numberOfImages; i++) {
      const config: Record<string, unknown> = {
        responseModalities: ["IMAGE"],
      };

      if (params.aspectRatio) config.imageConfig = { aspectRatio: params.aspectRatio };
      if (params.personGeneration) config.personGeneration = params.personGeneration;

      // Build content: reference images first, then prompt text
      const contents: (GeminiImagePart | { text: string })[] = [...refParts, { text: params.prompt }];

      const response = await this.client.models.generateContent({
        model: this.model,
        contents,
        config,
      });

      if (response.candidates?.[0]?.content?.parts) {
        for (const part of response.candidates[0].content.parts) {
          if (part.inlineData?.data) images.push(part.inlineData.data);
        }
      }
    }

    if (images.length === 0) throw new Error("No images generated by Gemini API");

    return images;
  }

  /**
   * Convert a ReferenceImage to GeminiImagePart
   */
  private async referenceToImagePart(ref: ReferenceImage): Promise<GeminiImagePart> {
    if (ref.url) {
      return this.urlToImagePart(ref.url);
    }

    if (ref.path) {
      const buffer = await fs.readFile(ref.path);
      const mimeType = ref.mimeType ?? this.detectMimeTypeFromPath(ref.path);
      return { inlineData: { mimeType, data: buffer.toString("base64") } };
    }

    if (ref.base64) {
      return { inlineData: { mimeType: ref.mimeType ?? "image/jpeg", data: ref.base64 } };
    }

    throw new Error("ReferenceImage must have url, path, or base64");
  }

  private detectMimeTypeFromPath(filePath: string): string {
    const ext = filePath.split(".").pop()?.toLowerCase();
    const mimeTypes: Record<string, string> = {
      png: "image/png",
      jpg: "image/jpeg",
      jpeg: "image/jpeg",
      gif: "image/gif",
      webp: "image/webp",
    };
    return mimeTypes[ext ?? ""] ?? "image/jpeg";
  }

  async editImage(params: EditImageParams): Promise<string> {
    const imageParts: (GeminiImagePart | { text: string })[] = [];

    for (const imageUrl of params.referenceImages) {
      const imagePart = await this.urlToImagePart(imageUrl);
      imageParts.push(imagePart);
    }

    imageParts.push({ text: params.prompt });

    const response = await this.client.models.generateContent({
      model: this.model,
      contents: imageParts,
      config: {
        responseModalities: ["image"],
        ...(params.aspectRatio && {
          outputImageAspectRatio: params.aspectRatio,
        }),
      },
    });

    if (response.candidates?.[0]?.content?.parts) {
      for (const part of response.candidates[0].content.parts) {
        if (part.inlineData?.data) return part.inlineData.data;
      }
    }

    throw new Error("No image generated by Gemini API");
  }

  private async urlToImagePart(url: string): Promise<GeminiImagePart> {
    const response = await fetch(url);
    if (!response.ok) throw new Error(`Failed to fetch image from URL: ${response.status}`);

    const arrayBuffer = await response.arrayBuffer();
    const base64 = Buffer.from(arrayBuffer).toString("base64");

    let mimeType = response.headers.get("content-type") || "image/jpeg";

    if (mimeType === "application/octet-stream" || !mimeType.startsWith("image/")) {
      if (url.includes(".png")) mimeType = "image/png";
      else if (url.includes(".webp")) mimeType = "image/webp";
      else mimeType = "image/jpeg";
    }

    return { inlineData: { mimeType, data: base64 } };
  }

  async analyzeImage(imageUrl: string, prompt?: string): Promise<string> {
    const imagePart = await this.urlToImagePart(imageUrl);
    const textPrompt = prompt || "Analyze this image in detail. Describe what you see.";

    const response = await this.client.models.generateContent({
      model: this.visionModel,
      contents: [imagePart, { text: textPrompt }],
    });

    const text = response.candidates?.[0]?.content?.parts?.find((part) => "text" in part);
    if (!text || !("text" in text) || !text.text) throw new Error("No text response from Gemini vision API");

    return text.text;
  }

  async analyzeImageFromBuffer(buffer: Buffer, mimeType: string, prompt?: string): Promise<string> {
    const base64 = buffer.toString("base64");
    const imagePart: GeminiImagePart = { inlineData: { mimeType, data: base64 } };
    const textPrompt = prompt || "Analyze this image in detail. Describe what you see.";

    const response = await this.client.models.generateContent({
      model: this.visionModel,
      contents: [imagePart, { text: textPrompt }],
    });

    const text = response.candidates?.[0]?.content?.parts?.find((part) => "text" in part);
    if (!text || !("text" in text) || !text.text) throw new Error("No text response from Gemini vision API");

    return text.text;
  }

  convertBase64ToBuffer(base64: string): Buffer {
    return Buffer.from(base64, "base64");
  }
}

export const geminiClient = new GeminiClient();
